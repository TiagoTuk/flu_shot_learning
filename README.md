# ğŸ¦  Flu Shot Learning â€” Prevendo VacinaÃ§Ã£o H1N1 e Sazonal  
**Projeto de Machine Learning | CompetiÃ§Ã£o DivenData**

Este projeto tem como objetivo prever a probabilidade de uma pessoa ter tomado as vacinas **H1N1** e **Sazonal**, utilizando tÃ©cnicas completas de Data Science aplicadas ao dataset disponibilizado pela competiÃ§Ã£o da **DivenData**.

---

## ğŸ¯ Objetivo do Projeto

Construir um pipeline de Machine Learning capaz de:

- Realizar limpeza e tratamento dos dados  
- Criar novas variÃ¡veis relevantes (feature engineering)  
- Selecionar os melhores atributos para cada previsÃ£o  
- Testar diferentes modelos  
- Ajustar hiperparÃ¢metros (hyperparameter tuning)  
- Construir prediÃ§Ãµes finais  
- Gerar o arquivo oficial de submissÃ£o no formato solicitado pela DivenData

---

## ğŸ“‚ Estrutura do Projeto

â”œâ”€â”€ data/

â”‚ â”œâ”€â”€ train_set.csv

â”‚ â”œâ”€â”€ test_set_features.csv

â”‚ â””â”€â”€ submission_format.csv

â”œâ”€â”€ notebooks/

â”‚ â””â”€â”€ flu_shot_learning.ipynb

â”œâ”€â”€ README.md

â””â”€â”€ requirements.txt


---

## ğŸ§¹ PreparaÃ§Ã£o dos Dados

As etapas de transformaÃ§Ã£o incluÃ­ram:

### âœ” Tratamento de valores ausentes  
- Mediana para variÃ¡veis numÃ©ricas  
- Moda para variÃ¡veis categÃ³ricas  

### âœ” ConversÃ£o de tipos  

### âœ” CriaÃ§Ã£o de novas features
- `family_size`  
- `education_level_num`  
- `health_behaviors_score`  
- `risk_awareness_score`  
- `opinion_gap`

### âœ” NormalizaÃ§Ã£o e PadronizaÃ§Ã£o  
- `StandardScaler` para variÃ¡veis de percepÃ§Ã£o  
- `MinMaxScaler` para variÃ¡veis contÃ­nuas  

### âœ” CodificaÃ§Ã£o categÃ³rica  
- One-hot encoding (`get_dummies`)  

---

## ğŸ” SeleÃ§Ã£o de Features

A seleÃ§Ã£o foi realizada utilizando:

- Random Forest  
- LightGBM  
- ExtraTrees  
- Ranking por importÃ¢ncia de features  
- ValidaÃ§Ã£o cruzada  

Isso gerou dois conjuntos finais:

- **Features para prever H1N1**  
- **Features para prever Vacina Sazonal**

---

## ğŸ¤– Modelos Testados

Foram testados e comparados:

- **Logistic Regression**  
- **Random Forest**  
- **LightGBM (modelo final escolhido)**  

O LightGBM apresentou o melhor desempenho geral.

---

## ğŸ”§ Tuning de HiperparÃ¢metros

Utilizado:

```python
RandomizedSearchCV(
    estimator=LGBMClassifier(),
    param_distributions=param_grid,
    n_iter=50,
    scoring='roc_auc',
    cv=5,
    random_state=42
)
```

ğŸ† Resultados Obtidos
| ğŸ”¬ Modelo | ğŸ¦  H1N1 (AUC) | ğŸ¤§ Gripe Sazonal (AUC) |
|----------|--------------|------------------------|
| Logistic Regression | 0.8447 | 0.8436 |
| Random Forest | 0.8075 | 0.8061|
| LightGBM | 0.8448 | 0.8475 |


ğŸ“ˆ Tecnologias Utilizadas

Python

Pandas / NumPy

Scikit-Learn

LightGBM

Matplotlib / Seaborn

Jupyter Notebook

ğŸ‘¨â€ğŸ’» Autor

Tiago Barros
Estudante de Big Data | Cientista de Dados em formaÃ§Ã£o

FATEC Ipiranga Â· SÃ£o Paulo, Brasil
